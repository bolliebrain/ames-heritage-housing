{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sale Price Prediction Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "## Inputs\n",
    "\n",
    "## Outputs\n",
    "\n",
    "## Additional Comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change working directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to change the working directory from its current folder to its parent folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We access the current directory with os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspace'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to make the parent of the current directory the new current directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* os.path.dirname() gets the parent directory\n",
    "* os.chir() defines the new current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You set a new current directory\n"
     ]
    }
   ],
   "source": [
    "os.chdir(os.path.dirname(current_dir))\n",
    "print(\"You set a new current directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm the new directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'outputs/datasets/collection/house_prices_records.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/workspace/ames-heritage-housing/jupyter_notebooks/05-SalePricePrediction.ipynb Cell 14\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell://bolliebrain-amesheritag-30bg062l2cf.ws-eu110.gitpod.io/workspace/ames-heritage-housing/jupyter_notebooks/05-SalePricePrediction.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpy\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://bolliebrain-amesheritag-30bg062l2cf.ws-eu110.gitpod.io/workspace/ames-heritage-housing/jupyter_notebooks/05-SalePricePrediction.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://bolliebrain-amesheritag-30bg062l2cf.ws-eu110.gitpod.io/workspace/ames-heritage-housing/jupyter_notebooks/05-SalePricePrediction.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m df_house_prices \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39moutputs/datasets/collection/house_prices_records.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell://bolliebrain-amesheritag-30bg062l2cf.ws-eu110.gitpod.io/workspace/ames-heritage-housing/jupyter_notebooks/05-SalePricePrediction.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m df_house_prices\u001b[39m.\u001b[39mhead()\n",
      "File \u001b[0;32m/workspace/.pyenv_mirror/user/3.8.18/lib/python3.8/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/workspace/.pyenv_mirror/user/3.8.18/lib/python3.8/site-packages/pandas/io/parsers/readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    665\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    666\u001b[0m     dialect,\n\u001b[1;32m    667\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    676\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[1;32m    677\u001b[0m )\n\u001b[1;32m    678\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 680\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m/workspace/.pyenv_mirror/user/3.8.18/lib/python3.8/site-packages/pandas/io/parsers/readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    572\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    574\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 575\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    577\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    578\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/workspace/.pyenv_mirror/user/3.8.18/lib/python3.8/site-packages/pandas/io/parsers/readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    930\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    932\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 933\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m/workspace/.pyenv_mirror/user/3.8.18/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1217\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1213\u001b[0m     mode \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1214\u001b[0m \u001b[39m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[1;32m   1215\u001b[0m \u001b[39m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[1;32m   1216\u001b[0m \u001b[39m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[0;32m-> 1217\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(  \u001b[39m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[1;32m   1218\u001b[0m     f,\n\u001b[1;32m   1219\u001b[0m     mode,\n\u001b[1;32m   1220\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1221\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1222\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m   1223\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[1;32m   1224\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1225\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1226\u001b[0m )\n\u001b[1;32m   1227\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1228\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[0;32m/workspace/.pyenv_mirror/user/3.8.18/lib/python3.8/site-packages/pandas/io/common.py:789\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    784\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    785\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    786\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    787\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[1;32m    788\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[1;32m    790\u001b[0m             handle,\n\u001b[1;32m    791\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[1;32m    792\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[1;32m    793\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m    794\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    795\u001b[0m         )\n\u001b[1;32m    796\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    797\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m    798\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'outputs/datasets/collection/house_prices_records.csv'"
     ]
    }
   ],
   "source": [
    "import numpy as py\n",
    "import pandas as pd\n",
    "\n",
    "df_house_prices = pd.read_csv(f\"outputs/datasets/collection/house_prices_records.csv\")\n",
    "df_house_prices.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Pipeline: Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the ML Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/.pyenv_mirror/user/3.8.18/lib/python3.8/site-packages/xgboost/compat.py:93: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Data Cleaning\n",
    "from feature_engine.selection import DropFeatures\n",
    "from feature_engine.imputation import CategoricalImputer\n",
    "from feature_engine.imputation import ArbitraryNumberImputer\n",
    "from feature_engine.imputation import MeanMedianImputer\n",
    "\n",
    "# Feature Engineering\n",
    "from feature_engine import transformation as vt\n",
    "from feature_engine.outliers import Winsorizer\n",
    "from feature_engine.encoding import OrdinalEncoder\n",
    "from feature_engine.selection import SmartCorrelatedSelection\n",
    "\n",
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Feature Selection\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# ML Algorithms\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Dropped features from smart correlation '1stFlrSF', 'GarageYrBlt', 'GrLivArea', 'YearRemodArea'\n",
    "\n",
    "def PipelineOptimization(model):\n",
    "    pipeline_base = Pipeline([\n",
    "        # Cleaning Pipeline\n",
    "        (\"DropFeatures\", DropFeatures(features_to_drop=['EnclosedPorch', 'WoodDeckSF'])),\n",
    "        (\"CategoricalImputer\", CategoricalImputer(imputation_method='missing', fill_value='Unf', variables=['BsmtFinType1', 'GarageFinish'])),\n",
    "        (\"ArbitraryNumberImputer\", ArbitraryNumberImputer(arbitrary_number=0, variables=['2ndFlrSF', 'MasVnrArea'])),\n",
    "        (\"MeanMedianImputer\", MeanMedianImputer(imputation_method='median', variables=['BedroomAbvGr', 'GarageYrBlt', 'LotFrontage'])),\n",
    "        # Feature Engineering\n",
    "        (\"NumericLogTransform\", vt.LogTransformer(variables=['1stFlrSF', 'GrLivArea'], base='e')),\n",
    "        (\"NumericYeoJohnsonTransform\", vt.YeoJohnsonTransformer(variables=['BsmtUnfSF', 'TotalBsmtSF', 'GarageArea'])),\n",
    "        (\"NumericPowerTransform\", vt.PowerTransformer(variables=['LotArea'])),\n",
    "        (\"Winsorizer\", Winsorizer(capping_method='iqr', tail='both', fold=1.5, variables=['GrLivArea'])),\n",
    "        (\"SmartCorrelationSelection\", SmartCorrelatedSelection(variables=None, method=\"spearman\", threshold=0.6, selection_method=\"variance\")),\n",
    "        # Feature Scaling\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        # Feature Selection\n",
    "        (\"feat_selection\", SelectFromModel(model)),\n",
    "        # ML Algorithms\n",
    "        (\"model\", model),\n",
    "    ])\n",
    "\n",
    "    return pipeline_base\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we create a custom class for hyperparameter optimisation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "class HyperparameterOptimizationSearch:\n",
    "\n",
    "    def __init__(self, models, params):\n",
    "        self.models = models\n",
    "        self.params = params\n",
    "        self.keys = models.keys()\n",
    "        self.grid_searches = {}\n",
    "\n",
    "        def fit(self, X, y, cv, n_jobs, verbose=1, scoring=None, refit=False):\n",
    "            for key in self.keys:\n",
    "                print(f\"\\nRunning GridSearchCV for {key} \\n\")\n",
    "                model = PipelineOptimization(self.models[key])\n",
    "\n",
    "                params = self.params[key]\n",
    "                gs = GridSearchCV(model, params, cv=cv, n_jobs=n_jobs,\n",
    "                                verbose=verbose, scoring=scoring)\n",
    "                gs.fit(X, y)\n",
    "                self.grid_searches[key] = gs\n",
    "        \n",
    "        def score_summary(self, sort_by='mean_score'):\n",
    "            def row(key, scores, params):\n",
    "                d = {\n",
    "                    'estimator': key,\n",
    "                    'min_score': min(scores),\n",
    "                    'max_score': max(scores),\n",
    "                    'mean_score': np.mean(scores),\n",
    "                    'std_score': np.std(scores),\n",
    "                }\n",
    "                return pd.Series({**params, **d})\n",
    "            \n",
    "            rows = []\n",
    "            for k in self.grid_searches:\n",
    "                params = self.grid_searches[k].cv_results_['params']\n",
    "                scores = []\n",
    "                for i in range(self.grid_searches[k].cv):\n",
    "                    key = \"split{}_test_score\".format(i)\n",
    "                    r = self.grid_searches[k].cv_results_[key]\n",
    "                    scores.append(r.reshape(len(params), 1))\n",
    "                \n",
    "                all_scores = np.hstack(scores)\n",
    "                for p, s in zip(params, all_scores):\n",
    "                    rows.append((row(k, s, p)))\n",
    "            \n",
    "            df = pd.concat(rows, axis=1).T.sort_values([sort_by], ascending=False),\n",
    "\n",
    "            columns = ['estimator', 'min_score', 'mean_score', 'max_score', 'std_score']\n",
    "            columns = columns + [c for c in df.columns if c not in columns]\n",
    "\n",
    "            return df[columns], self.grid_searches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Train and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/workspace/ames-heritage-housing/jupyter_notebooks/05-SalePricePrediction.ipynb Cell 21\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell://bolliebrain-amesheritag-30bg062l2cf.ws-eu110.gitpod.io/workspace/ames-heritage-housing/jupyter_notebooks/05-SalePricePrediction.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_selection\u001b[39;00m \u001b[39mimport\u001b[39;00m train_test_split\n\u001b[1;32m      <a href='vscode-notebook-cell://bolliebrain-amesheritag-30bg062l2cf.ws-eu110.gitpod.io/workspace/ames-heritage-housing/jupyter_notebooks/05-SalePricePrediction.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m X_train, X_test, y_train, y_test \u001b[39m=\u001b[39m train_test_split(\n\u001b[0;32m----> <a href='vscode-notebook-cell://bolliebrain-amesheritag-30bg062l2cf.ws-eu110.gitpod.io/workspace/ames-heritage-housing/jupyter_notebooks/05-SalePricePrediction.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     df\u001b[39m.\u001b[39mdrop([\u001b[39m'\u001b[39m\u001b[39mSalePrice\u001b[39m\u001b[39m'\u001b[39m], axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m),\n\u001b[1;32m      <a href='vscode-notebook-cell://bolliebrain-amesheritag-30bg062l2cf.ws-eu110.gitpod.io/workspace/ames-heritage-housing/jupyter_notebooks/05-SalePricePrediction.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m     df[\u001b[39m'\u001b[39m\u001b[39mSalePrice\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m      <a href='vscode-notebook-cell://bolliebrain-amesheritag-30bg062l2cf.ws-eu110.gitpod.io/workspace/ames-heritage-housing/jupyter_notebooks/05-SalePricePrediction.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m     test_size\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell://bolliebrain-amesheritag-30bg062l2cf.ws-eu110.gitpod.io/workspace/ames-heritage-housing/jupyter_notebooks/05-SalePricePrediction.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m     random_state\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell://bolliebrain-amesheritag-30bg062l2cf.ws-eu110.gitpod.io/workspace/ames-heritage-housing/jupyter_notebooks/05-SalePricePrediction.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell://bolliebrain-amesheritag-30bg062l2cf.ws-eu110.gitpod.io/workspace/ames-heritage-housing/jupyter_notebooks/05-SalePricePrediction.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m* Train set:\u001b[39m\u001b[39m\"\u001b[39m, X_train\u001b[39m.\u001b[39mshape, y_train\u001b[39m.\u001b[39mshape,\n\u001b[1;32m     <a href='vscode-notebook-cell://bolliebrain-amesheritag-30bg062l2cf.ws-eu110.gitpod.io/workspace/ames-heritage-housing/jupyter_notebooks/05-SalePricePrediction.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m      \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m* Test set:\u001b[39m\u001b[39m\"\u001b[39m, X_test\u001b[39m.\u001b[39mshape, y_test\u001b[39m.\u001b[39mshape)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.drop(['SalePrice'], axis=1),\n",
    "    df['SalePrice'],\n",
    "    test_size=0.2,\n",
    "    random_state=0,\n",
    ")\n",
    "\n",
    "print(\"* Train set:\", X_train.shape, y_train.shape,\n",
    "     \"\\n* Test set:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search CV - Sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use deault hyperparameters first to find most suitable algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_search = {\n",
    "    'LinearRegression': LinearRegression(),\n",
    "    \"DecisionTreeRegressor\": DecisionTreeRegressor(random_state=0),\n",
    "    \"RandomForestRegressor\": RandomForestRegressor(random_state=0),\n",
    "    \"ExtraTreesRegressor\": ExtraTreesRegressor(random_state=0),\n",
    "    \"AdaBoostRegressor\": AdaBoostRegressor(random_state=0),\n",
    "    \"GradientBoostingRegressor\": GradientBoostingRegressor(random_state=0),\n",
    "    \"XGBRegressor\": XGBRegressor(random_state=0),\n",
    "}\n",
    "\n",
    "params_search = {\n",
    "    'LinearRegression': {},\n",
    "    \"DecisionTreeRegressor\": {},\n",
    "    \"RandomForestRegressor\": {},\n",
    "    \"ExtraTreesRegressor\": {},\n",
    "    \"AdaBoostRegressor\": {},\n",
    "    \"GradientBoostingRegressor\": {},\n",
    "    \"XGBRegressor\": {},\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will conduct the search using these default hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = HyperparameterOptimizationSearch(models=models_search, params=params_search),\n",
    "search.fit(X_train, y_train, scoring='r2', n_jobs=-1, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the results of the grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_summary, grid_search_pipelines = search.score_summary(sort_by='mean_score'),\n",
    "grid_search_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Findings:\n",
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding The Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = grid_search_summary.iloc[0,0]\n",
    "best_model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
